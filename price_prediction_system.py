"""
ç²¾ç®€ç‰ˆLSTMä»·æ ¼é¢„æµ‹ç³»ç»Ÿ
- æ ¸å¿ƒLSTMæ¨¡å‹
- åŸºç¡€æ•°æ®å¤„ç†
- ç®€åŒ–çš„Webç•Œé¢
"""

# è§£å†³PyTorchä¸Streamlitçš„å…¼å®¹æ€§é—®é¢˜
import sys
import os
import importlib.util

# åœ¨å¯¼å…¥torchä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['TORCH_SHOW_CPP_STACKTRACES'] = '0'

# ç¦ç”¨Streamlitçš„æ–‡ä»¶ç›‘è§†å™¨å¯¹torchæ¨¡å—çš„æ£€æŸ¥
if 'torch' not in sys.modules:
    # é¢„åŠ è½½torchä»¥é¿å…Streamlitçš„æ¨¡å—è·¯å¾„æ£€æŸ¥é—®é¢˜
    try:
        import torch
        # ä¿®å¤torch.classesçš„__path__é—®é¢˜
        if hasattr(torch, 'classes'):
            if not hasattr(torch.classes, '__path__'):
                torch.classes.__path__ = []
    except ImportError:
        pass

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
import streamlit as st
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os
from multi_source_fetcher import MultiSourceDataFetcher

warnings.filterwarnings('ignore')

class SimpleLSTMPredictor(nn.Module):
    """ç®€åŒ–çš„LSTMé¢„æµ‹æ¨¡å‹"""
    def __init__(self, input_size=5, hidden_size=64, num_layers=2, dropout=0.2):
        super(SimpleLSTMPredictor, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0,
            batch_first=True
        )
        
        self.fc = nn.Linear(hidden_size, 1)  # åªé¢„æµ‹æ”¶ç›˜ä»·
        
    def forward(self, x):
        batch_size = x.size(0)
        
        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)
        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)
        
        lstm_out, _ = self.lstm(x, (h0, c0))
        out = self.fc(lstm_out[:, -1, :])
        
        return out

class SimpleLSTMSystem:
    """ç®€åŒ–çš„LSTMä»·æ ¼é¢„æµ‹ç³»ç»Ÿ"""
    
    def __init__(self, symbol="DOGEUSDT", sequence_length=30):
        self.symbol = symbol
        self.sequence_length = sequence_length
        # è‡ªåŠ¨æ£€æµ‹ GPU
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model: SimpleLSTMPredictor | None = None
        self.scaler = MinMaxScaler()
        
    def prepare_data(self, data):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # åªä½¿ç”¨OHLCVåŸºç¡€æ•°æ®
        feature_columns = ['open', 'high', 'low', 'close', 'volume']
        data = data[feature_columns].copy()
        
        # æ ‡å‡†åŒ–æ•°æ®
        scaled_data = self.scaler.fit_transform(data)
        
        # åˆ›å»ºåºåˆ—æ•°æ®
        X, y = [], []
        for i in range(self.sequence_length, len(scaled_data)):
            X.append(scaled_data[i-self.sequence_length:i])
            y.append(scaled_data[i, 3])  # æ”¶ç›˜ä»·
            
        return np.array(X), np.array(y)
    
    def train_model(self, X, y, epochs=50, learning_rate=0.001):
        """è®­ç»ƒæ¨¡å‹"""
        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶ç§»åŠ¨åˆ° device
        X_train = torch.tensor(X_train, dtype=torch.float32, device=self.device)
        y_train = torch.tensor(y_train, dtype=torch.float32, device=self.device).unsqueeze(1)
        X_test = torch.tensor(X_test, dtype=torch.float32, device=self.device)
        y_test = torch.tensor(y_test, dtype=torch.float32, device=self.device).unsqueeze(1)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(X_train, y_train)
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = SimpleLSTMPredictor(input_size=X.shape[2]).to(self.device)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        
        # è®­ç»ƒ
        train_losses = []
        for epoch in range(epochs):
            epoch_loss = 0
            for batch_X, batch_y in train_loader:
                optimizer.zero_grad()
                batch_X = batch_X.to(self.device)
                batch_y = batch_y.to(self.device)
                outputs = self.model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
            
            train_losses.append(epoch_loss / len(train_loader))
        
        # è¯„ä¼°
        self.model.eval()
        with torch.no_grad():
            test_pred = self.model(X_test)
            test_loss = criterion(test_pred, y_test).item()
        
        return train_losses, test_loss
    
    def predict_future(self, data, prediction_hours=24):
        """é¢„æµ‹æœªæ¥ä»·æ ¼"""
        if self.model is None:
            return None
            
        # å‡†å¤‡æœ€åä¸€æ®µæ•°æ®
        feature_columns = ['open', 'high', 'low', 'close', 'volume']
        last_data = data[feature_columns].tail(self.sequence_length)
        scaled_data = self.scaler.transform(last_data)
        
        # é¢„æµ‹
        predictions = []
        current_seq = scaled_data.copy()
        
        self.model.eval()
        with torch.no_grad():
            for i in range(prediction_hours):
                X = torch.tensor(current_seq, dtype=torch.float32, device=self.device).unsqueeze(0)
                pred = self.model(X).cpu()
                predictions.append(pred.item())
                
                # æ›´æ–°åºåˆ— - æ›´æ™ºèƒ½çš„æ–¹å¼
                next_row = current_seq[-1].copy()
                
                # è€ƒè™‘ä»·æ ¼çš„åˆç†å˜åŠ¨èŒƒå›´ï¼Œé¿å…è¿‡åº¦é¢„æµ‹
                if i < prediction_hours - 1:
                    # é™åˆ¶å•æ­¥é¢„æµ‹çš„å˜åŒ–å¹…åº¦
                    pred_value = pred.item()
                    last_pred = predictions[-2] if len(predictions) > 1 else current_seq[-1][3]
                    max_change = 0.1  # é™åˆ¶å•æ­¥æœ€å¤§å˜åŒ–ä¸º10%
                    
                    if abs(pred_value - last_pred) / abs(last_pred) > max_change:
                        if pred_value > last_pred:
                            pred_value = last_pred * (1 + max_change)
                        else:
                            pred_value = last_pred * (1 - max_change)
                        predictions[-1] = pred_value
                    
                    next_row[3] = pred_value  # æ›´æ–°æ”¶ç›˜ä»·
                else:
                    next_row[3] = pred.item()
                
                # æ›´æ–°å…¶ä»–ä»·æ ¼å­—æ®µï¼ˆç®€å•ä¼°ç®—ï¼‰
                current_close = next_row[3]
                next_row[0] = current_close * (0.999 + np.random.uniform(-0.001, 0.001))  # open
                next_row[1] = current_close * (1.0 + abs(np.random.uniform(0, 0.002)))   # high
                next_row[2] = current_close * (1.0 - abs(np.random.uniform(0, 0.002)))   # low
                
                current_seq = np.vstack([current_seq[1:], next_row])
        
        # åæ ‡å‡†åŒ–é¢„æµ‹ç»“æœ
        dummy_data = np.zeros((len(predictions), 5))
        dummy_data[:, 3] = predictions
        predictions_unscaled = self.scaler.inverse_transform(dummy_data)[:, 3]
        
        # åˆ›å»ºæ—¶é—´ç´¢å¼•
        last_time = data.index[-1]
        time_index = pd.date_range(
            start=last_time + timedelta(minutes=15),
            periods=prediction_hours,
            freq='15T'
        )
        
        return pd.DataFrame({
            'predicted_close': predictions_unscaled
        }, index=time_index)

def main():
    """ä¸»WebUIåº”ç”¨"""
    st.set_page_config(
        page_title="LSTMä»·æ ¼é¢„æµ‹ç³»ç»Ÿ",
        page_icon="ğŸ”®",
        layout="wide"
    )
    
    st.title("ğŸ”® LSTMä»·æ ¼é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("**åŸºäºLSTMç¥ç»ç½‘ç»œçš„åŠ å¯†è´§å¸ä»·æ ¼é¢„æµ‹**")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é¢„æµ‹é…ç½®")
        
        symbol = st.selectbox("é€‰æ‹©äº¤æ˜“å¯¹", [
            "DOGEUSDT", "BTCUSDT", "ETHUSDT", "ADAUSDT"
        ])
        
        sequence_length = st.slider("åºåˆ—é•¿åº¦", 20, 60, 30)
        prediction_hours = st.slider("é¢„æµ‹æ—¶é•¿ (å°æ—¶)", 1, 72, 24)
        epochs = st.slider("è®­ç»ƒè½®æ•°", 20, 200, 50)
        target_points = st.number_input("å†å²Kçº¿æ•°é‡", 500, 10000, 5000, step=500)
        
        if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
            st.session_state.run_prediction = True
            st.session_state.target_points = int(target_points)
    
    # ä¸»ç•Œé¢
    if st.session_state.get('run_prediction', False):
        run_prediction(symbol, sequence_length, prediction_hours, epochs, st.session_state.get('target_points', 5000))

def run_prediction(symbol, sequence_length, prediction_hours, epochs, target_points):
    """è¿è¡Œé¢„æµ‹"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # è·å–æ•°æ®
        status_text.text("ğŸ“Š æ­£åœ¨è·å–å†å²æ•°æ®...")
        progress_bar.progress(20)
        
        fetcher = MultiSourceDataFetcher(symbol)
        source, historical_data = fetcher.fetch_large_dataset(target_points=target_points)
        
        if historical_data is None or len(historical_data) < 100:
            st.error("âŒ æ— æ³•è·å–è¶³å¤Ÿçš„å†å²æ•°æ®")
            return
            
        # éªŒè¯æ•°æ®è´¨é‡
        if historical_data['close'].std() < 0.000001:
            st.error("âŒ æ•°æ®è´¨é‡é—®é¢˜ï¼šä»·æ ¼å˜åŒ–å¤ªå°ï¼Œå¯èƒ½æ˜¯æ— æ•ˆæ•°æ®")
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
        price_range = historical_data['close'].max() - historical_data['close'].min()
        if price_range < historical_data['close'].mean() * 0.01:
            st.warning("âš ï¸ è­¦å‘Šï¼šä»·æ ¼å˜åŒ–èŒƒå›´å¾ˆå°ï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä¸å‡†ç¡®")
        
        progress_bar.progress(40)
        current_price = historical_data['close'].iloc[-1]
        
        # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯å’ŒåŸºæœ¬ç»Ÿè®¡
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ•°æ®é‡", f"{len(historical_data)}æ¡")
        with col2:
            st.metric("å½“å‰ä»·æ ¼", f"{current_price:.6f}")
        with col3:
            st.metric("æ•°æ®æº", source)
        
        # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        st.write("ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æœ€ä½ä»·", f"{historical_data['close'].min():.6f}")
        with col2:
            st.metric("æœ€é«˜ä»·", f"{historical_data['close'].max():.6f}")
        with col3:
            st.metric("ä»·æ ¼æ ‡å‡†å·®", f"{historical_data['close'].std():.6f}")
        with col4:
            st.metric("æ•°æ®æ—¶é—´è·¨åº¦", f"{(historical_data.index[-1] - historical_data.index[0]).days}å¤©")
        
        # è®­ç»ƒæ¨¡å‹
        status_text.text("ğŸ§  æ­£åœ¨è®­ç»ƒLSTMæ¨¡å‹...")
        progress_bar.progress(60)
        
        predictor = SimpleLSTMSystem(symbol, sequence_length)
        X, y = predictor.prepare_data(historical_data)
        
        train_losses, test_loss = predictor.train_model(X, y, epochs)
        
        progress_bar.progress(80)
        
        # é¢„æµ‹
        status_text.text("ğŸ”® æ­£åœ¨ç”Ÿæˆé¢„æµ‹...")
        predictions = predictor.predict_future(historical_data, prediction_hours)
        
        progress_bar.progress(100)
        status_text.text("âœ… é¢„æµ‹å®Œæˆ!")
        
        if predictions is not None:
            predicted_price = predictions['predicted_close'].iloc[-1]
            change_pct = ((predicted_price - current_price) / current_price) * 100
            
            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("é¢„æµ‹ä»·æ ¼", f"{predicted_price:.6f}")
            with col2:
                st.metric("å˜åŒ–å¹…åº¦", f"{change_pct:+.2f}%")
            with col3:
                st.metric("æµ‹è¯•æŸå¤±", f"{test_loss:.6f}")
            
            # ç»˜åˆ¶å›¾è¡¨
            fig = go.Figure()
            
            # è·å–æ›´å¤šå†å²æ•°æ®ä»¥æ˜¾ç¤ºæ›´å¥½çš„è¶‹åŠ¿
            recent_data = historical_data.tail(200)  # å¢åŠ æ•°æ®ç‚¹
            
            # ç¡®ä¿ç´¢å¼•æ˜¯datetimeæ ¼å¼
            if not isinstance(recent_data.index, pd.DatetimeIndex):
                recent_data.index = pd.to_datetime(recent_data.index)
            if not isinstance(predictions.index, pd.DatetimeIndex):
                predictions.index = pd.to_datetime(predictions.index)
            
            # å†å²ä»·æ ¼
            fig.add_trace(go.Scatter(
                x=recent_data.index,
                y=recent_data['close'],
                name="å†å²ä»·æ ¼",
                line=dict(color='blue', width=2),
                mode='lines'
            ))
            
            # é¢„æµ‹ä»·æ ¼
            fig.add_trace(go.Scatter(
                x=predictions.index,
                y=predictions['predicted_close'],
                name="é¢„æµ‹ä»·æ ¼",
                line=dict(color='red', dash='dash', width=2),
                mode='lines'
            ))
            
            # æ·»åŠ å½“å‰ä»·æ ¼è¿æ¥çº¿
            connection_x = [recent_data.index[-1], predictions.index[0]]
            connection_y = [recent_data['close'].iloc[-1], predictions['predicted_close'].iloc[0]]
            fig.add_trace(go.Scatter(
                x=connection_x,
                y=connection_y,
                mode='lines',
                line=dict(color='orange', width=2, dash='dot'),
                name="è¿æ¥çº¿",
                showlegend=False
            ))
            
            fig.update_layout(
                title=f"{symbol} LSTMä»·æ ¼é¢„æµ‹",
                xaxis_title="æ—¶é—´",
                yaxis_title="ä»·æ ¼ (USDT)",
                height=600,
                xaxis=dict(
                    type='date',
                    tickformat='%H:%M<br>%m/%d'
                ),
                yaxis=dict(
                    tickformat='.6f'
                ),
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # æ˜¾ç¤ºé¢„æµ‹æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
            with st.expander("ğŸ” é¢„æµ‹è¯¦æƒ…"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**å†å²æ•°æ®ï¼ˆæœ€è¿‘20æ¡ï¼‰:**")
                    st.dataframe(recent_data[['close']].tail(20), height=200)
                with col2:
                    st.write("**é¢„æµ‹æ•°æ®:**")
                    pred_df = predictions.copy()
                    pred_df['time'] = pred_df.index.strftime('%H:%M %m/%d')
                    st.dataframe(pred_df[['predicted_close', 'time']].head(24), height=200)
            
            # è®­ç»ƒå†å²
            with st.expander("ğŸ“ˆ è®­ç»ƒæŸå¤±"):
                fig_loss = go.Figure()
                fig_loss.add_trace(go.Scatter(
                    y=train_losses,
                    name="è®­ç»ƒæŸå¤±",
                    line=dict(color='blue')
                ))
                fig_loss.update_layout(
                    title="LSTMè®­ç»ƒæŸå¤±æ›²çº¿",
                    xaxis_title="è½®æ•°",
                    yaxis_title="æŸå¤±å€¼"
                )
                st.plotly_chart(fig_loss, use_container_width=True)
        
    except Exception as e:
        st.error(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main() 